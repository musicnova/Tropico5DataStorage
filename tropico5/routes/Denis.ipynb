{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "data_dir = '/home/user/ALBINA/DENIS'\n",
    "\n",
    "# 22834"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0      1                      2     3                      4   \\\n",
      "1  1   2566  2017-12-19 14:12:23.0  2163  2017-12-19 12:16:29.0   \n",
      "2  2   6867  2017-12-18 21:08:58.0    44  2017-12-18 18:29:46.0   \n",
      "3  3  16590  2017-12-20 20:43:41.0   378  2017-12-20 10:25:36.0   \n",
      "\n",
      "                      5                      6                      7   \\\n",
      "1  2017-12-19 11:19:52.0  2017-12-19 09:17:22.0  2017-12-18 11:27:45.0   \n",
      "2  2017-12-12 09:51:49.0  2017-12-12 08:36:10.0  2017-11-24 15:13:18.0   \n",
      "3  2017-12-19 20:42:22.0  2017-12-19 10:12:23.0  2017-12-18 20:36:49.0   \n",
      "\n",
      "                      8                      9  ...    13   14    15    16  \\\n",
      "1  2017-12-18 09:19:58.0  2017-12-15 10:32:43.0 ...   124  318  2185  2143   \n",
      "2  2017-11-24 13:45:34.0  2017-11-15 21:29:34.0 ...  2020   90  2020   366   \n",
      "3  2017-12-18 10:08:01.0  2017-12-15 20:28:49.0 ...   237  378   237   207   \n",
      "\n",
      "     17    18    19   20   21  22  \n",
      "1  2147  2147  2149   27   29  38  \n",
      "2   190   207   190  366  190  10  \n",
      "3   237   378   237  378  237  44  \n",
      "\n",
      "[3 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.read_csv(os.path.join(data_dir, 'part1.csv.csv'), sep=',', header=None)\n",
    "df1 = df1[df1.index>0]\n",
    "print (df1.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0         1                      2    3                      4   \\\n",
      "1  5001  12234159  2017-12-08 14:37:28.0  213  2017-12-08 14:37:25.0   \n",
      "2  5002  12235880  2017-12-20 17:51:18.0   64  2017-12-20 08:02:24.0   \n",
      "3  5003  12252824  2017-12-19 21:42:14.0  320  2017-12-19 08:14:55.0   \n",
      "\n",
      "                      5                      6                      7   \\\n",
      "1  2017-12-08 12:47:56.0  2017-11-04 11:36:13.0                    NaN   \n",
      "2  2017-12-19 19:17:41.0  2017-12-19 08:00:19.0  2017-12-18 17:27:12.0   \n",
      "3  2017-12-17 21:35:22.0  2017-12-17 08:07:33.0  2017-12-14 22:32:18.0   \n",
      "\n",
      "                      8                      9  ...   13  14   15   16   17  \\\n",
      "1                    NaN                    NaN ...  213  38   66  NaN  NaN   \n",
      "2  2017-12-18 07:47:02.0  2017-12-14 08:29:44.0 ...   24  66   24   64   24   \n",
      "3  2017-12-14 08:00:50.0  2017-12-12 08:10:16.0 ...  296  47  296   47  296   \n",
      "\n",
      "    18   19   20   21  22  \n",
      "1  NaN  NaN  NaN  NaN   4  \n",
      "2   24   64   24   64  57  \n",
      "3  296  320  296  320  61  \n",
      "\n",
      "[3 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df2 = pd.read_csv(os.path.join(data_dir, 'part2.csv.csv'), sep=',', header=None)\n",
    "df2 = df2[df2.index>0]\n",
    "print (df2.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0           1                      2   3                      4   \\\n",
      "1  10001  3951129083  2017-12-21 00:48:54.0  47  2017-12-20 19:58:07.0   \n",
      "2  10002  3951141552  2017-12-20 18:44:45.0  98  2017-12-19 18:47:05.0   \n",
      "3  10003  3951152990  2017-12-20 19:07:01.0  40  2017-12-20 08:40:04.0   \n",
      "\n",
      "                      5                      6                      7   \\\n",
      "1  2017-12-20 00:15:54.0  2017-12-19 19:12:00.0  2017-12-18 23:30:59.0   \n",
      "2  2017-12-19 08:05:18.0  2017-12-19 08:05:15.0  2017-12-18 18:41:38.0   \n",
      "3  2017-12-19 19:07:06.0  2017-12-19 08:38:27.0  2017-12-18 19:08:12.0   \n",
      "\n",
      "                      8                      9  ...    13    14    15   16  \\\n",
      "1  2017-12-18 20:16:25.0  2017-12-17 19:14:21.0 ...   336   209   336  327   \n",
      "2  2017-12-18 07:56:13.0  2017-12-14 18:45:30.0 ...    98  2092  2092  327   \n",
      "3  2017-12-18 08:34:22.0  2017-12-15 20:11:55.0 ...  1006    40  1006   40   \n",
      "\n",
      "     17   18    19    20    21  22  \n",
      "1   336  333  2149  2141   336  54  \n",
      "2   297   98   297    98  2093  75  \n",
      "3  1006  318  1006    40   386  70  \n",
      "\n",
      "[3 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df3 = pd.read_csv(os.path.join(data_dir, 'part3.csv.csv'), sep=',', header=None)\n",
    "df3 = df3[df3.index>0]\n",
    "print (df3.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0        1                      2    3                      4   \\\n",
      "1  15001  6171344  2017-12-20 20:40:43.0  107  2017-12-20 09:53:08.0   \n",
      "2  15002  6182522  2017-12-13 20:23:17.0   90  2017-12-06 12:48:31.0   \n",
      "3  15003  6209440  2017-12-20 20:13:44.0   38  2017-12-19 18:44:34.0   \n",
      "\n",
      "                      5                      6                      7   \\\n",
      "1  2017-12-19 19:46:20.0  2017-12-19 09:21:59.0  2017-12-18 18:40:49.0   \n",
      "2  2017-12-05 18:08:32.0  2017-11-18 10:15:42.0  2017-11-07 09:10:50.0   \n",
      "3  2017-12-18 19:51:04.0  2017-12-15 19:21:50.0  2017-12-14 19:35:23.0   \n",
      "\n",
      "                      8                      9  ...    13    14    15    16  \\\n",
      "1  2017-12-18 10:03:49.0  2017-12-13 17:14:35.0 ...   109   107   109   107   \n",
      "2                    NaN                    NaN ...  2141  2159  2141  2157   \n",
      "3  2017-12-13 19:14:23.0  2017-12-12 18:37:36.0 ...    38    38    40    40   \n",
      "\n",
      "    17   18   19   20   21  22  \n",
      "1  109  211  198  109  320  77  \n",
      "2  NaN  NaN  NaN  NaN  NaN   5  \n",
      "3   40   38   40   38   38  41  \n",
      "\n",
      "[3 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df4 = pd.read_csv(os.path.join(data_dir, 'part4.csv.csv'), sep=',', header=None)\n",
    "df4 = df4[df4.index>0]\n",
    "print (df4.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0         1                      2    3                      4   \\\n",
      "1  20001  13092257  2017-12-15 13:28:56.0   73  2017-12-15 12:40:33.0   \n",
      "2  20002  13101112  2017-12-16 20:55:05.0  132  2017-12-16 19:48:21.0   \n",
      "3  20003  13103263  2017-12-20 19:08:53.0  267  2017-12-20 08:59:49.0   \n",
      "\n",
      "                      5                      6                      7   \\\n",
      "1  2017-12-10 20:11:47.0  2017-12-09 07:03:45.0  2017-12-07 16:08:53.0   \n",
      "2  2017-12-16 17:41:15.0  2017-12-16 13:09:12.0  2017-12-14 16:53:58.0   \n",
      "3  2017-12-19 19:10:19.0  2017-12-19 09:06:01.0  2017-12-19 08:21:02.0   \n",
      "\n",
      "                      8                      9  ...  13   14    15    16  \\\n",
      "1  2017-12-07 15:09:24.0  2017-12-07 13:23:05.0 ...  81  245    82   205   \n",
      "2  2017-12-14 15:40:27.0  2017-12-13 16:58:18.0 ...  41  100  2181  1002   \n",
      "3  2017-12-18 19:08:51.0  2017-12-18 09:00:05.0 ...  79  262    79   830   \n",
      "\n",
      "     17   18    19    20   21  22  \n",
      "1    52   82   408    82   52  19  \n",
      "2  2181  333  2146  2181  218  21  \n",
      "3   267   79   267    79  267  74  \n",
      "\n",
      "[3 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df5 = pd.read_csv(os.path.join(data_dir, 'part5.csv.csv'), sep=',', header=None)\n",
    "df5 = df5[df5.index>0]\n",
    "print (df5.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        crd_no               psg_date pl_id\n",
      "1115  10000699  2017-12-13 22:38:56.0   368\n",
      "1115  10000699  2017-12-14 09:32:41.0   242\n",
      "1115  10000699  2017-12-14 22:51:02.0   368\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_ok0 = pd.concat([df1[[1,2,3]], df2[[1,2,3]], df3[[1,2,3]], df4[[1,2,3]], df5[[1,2,3]]])\n",
    "df_ok0 = df_ok0.rename(columns={1: 'crd_no', 2: 'psg_date', 3: 'pl_id'})\n",
    "i=0\n",
    "df_ok1 = pd.concat([df1[[1,4+i,13+i]], df2[[1,4+i,13+i]], df3[[1,4+i,13+i]], df4[[1,4+i,13+i]], df5[[1,4+i,13+i]]])\n",
    "df_ok1 = df_ok1.rename(columns={1: 'crd_no', 4+i: 'psg_date', 13+i: 'pl_id'})\n",
    "i=1\n",
    "df_ok2 = pd.concat([df1[[1,4+i,13+i]], df2[[1,4+i,13+i]], df3[[1,4+i,13+i]], df4[[1,4+i,13+i]], df5[[1,4+i,13+i]]])\n",
    "df_ok2 = df_ok2.rename(columns={1: 'crd_no', 4+i: 'psg_date', 13+i: 'pl_id'})\n",
    "i=2\n",
    "df_ok3 = pd.concat([df1[[1,4+i,13+i]], df2[[1,4+i,13+i]], df3[[1,4+i,13+i]], df4[[1,4+i,13+i]], df5[[1,4+i,13+i]]])\n",
    "df_ok3 = df_ok3.rename(columns={1: 'crd_no', 4+i: 'psg_date', 13+i: 'pl_id'})\n",
    "i=3\n",
    "df_ok4 = pd.concat([df1[[1,4+i,13+i]], df2[[1,4+i,13+i]], df3[[1,4+i,13+i]], df4[[1,4+i,13+i]], df5[[1,4+i,13+i]]])\n",
    "df_ok4 = df_ok4.rename(columns={1: 'crd_no', 4+i: 'psg_date', 13+i: 'pl_id'})\n",
    "i=4\n",
    "df_ok5 = pd.concat([df1[[1,4+i,13+i]], df2[[1,4+i,13+i]], df3[[1,4+i,13+i]], df4[[1,4+i,13+i]], df5[[1,4+i,13+i]]])\n",
    "df_ok5 = df_ok5.rename(columns={1: 'crd_no', 4+i: 'psg_date', 13+i: 'pl_id'})\n",
    "i=5\n",
    "df_ok6 = pd.concat([df1[[1,4+i,13+i]], df2[[1,4+i,13+i]], df3[[1,4+i,13+i]], df4[[1,4+i,13+i]], df5[[1,4+i,13+i]]])\n",
    "df_ok6 = df_ok6.rename(columns={1: 'crd_no', 4+i: 'psg_date', 13+i: 'pl_id'})\n",
    "i=6\n",
    "df_ok7 = pd.concat([df1[[1,4+i,13+i]], df2[[1,4+i,13+i]], df3[[1,4+i,13+i]], df4[[1,4+i,13+i]], df5[[1,4+i,13+i]]])\n",
    "df_ok7 = df_ok7.rename(columns={1: 'crd_no', 4+i: 'psg_date', 13+i: 'pl_id'})\n",
    "i=7\n",
    "df_ok8 = pd.concat([df1[[1,4+i,13+i]], df2[[1,4+i,13+i]], df3[[1,4+i,13+i]], df4[[1,4+i,13+i]], df5[[1,4+i,13+i]]])\n",
    "df_ok8 = df_ok8.rename(columns={1: 'crd_no', 4+i: 'psg_date', 13+i: 'pl_id'})\n",
    "i=8\n",
    "df_ok9 = pd.concat([df1[[1,4+i,13+i]], df2[[1,4+i,13+i]], df3[[1,4+i,13+i]], df4[[1,4+i,13+i]], df5[[1,4+i,13+i]]])\n",
    "df_ok9 = df_ok9.rename(columns={1: 'crd_no', 4+i: 'psg_date', 13+i: 'pl_id'})\n",
    "df_ok = pd.concat([df_ok0, df_ok1, df_ok2, df_ok3, df_ok4, df_ok5, df_ok6, df_ok7, df_ok8, df_ok9])\n",
    "df_ok = df_ok.dropna()\n",
    "df_ok = df_ok.sort_values(by=['crd_no', 'psg_date'])\n",
    "print (df_ok.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crd_no</th>\n",
       "      <th>psg_date</th>\n",
       "      <th>pl_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [crd_no, psg_date, pl_id]\n",
       "Index: []"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ok.loc[df_ok['pl_id']=='']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_ok.to_csv(os.path.join(data_dir, 'ok.csv'), header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                0                       1                  2  \\\n",
      "0  номер телефона  последний номер тройки  все номера тройки   \n",
      "1     79036178580              0005120018         0005120018   \n",
      "2     79263224617              0000260296         0000260296   \n",
      "\n",
      "                    3  \n",
      "0  Кол-во номер троек  \n",
      "1                   1  \n",
      "2                   1  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_todo = pd.read_csv(os.path.join(data_dir, 'TODO.csv'), sep=';', header=None)\n",
    "print (df_todo.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/user/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29290\n",
      "                                                   V\n",
      "G                                                   \n",
      "0  (0012229164, 3951164125, 0006245593, 001265924...\n",
      "1  (0005120018, 0009940503, 0000513380, 001279984...\n",
      "2  (0000260296, 0006120752, 3951293138, 001233124...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "df = df_todo[df_todo[3] == '1']\n",
    "df['I'] = df.index\n",
    "df['V'] = df[1]\n",
    "df['G'] = df.apply(lambda row: int(row['I']) % 30, axis=1)\n",
    "df[['V']].to_csv(os.path.join(data_dir, '0.csv'), header=None, index=False, quoting=None)\n",
    "print (len(df))\n",
    "gr = df.groupby(['G'])['V'].apply(lambda x: \"(%s)\" % ', '.join(x))\n",
    "df_res = gr.to_frame()\n",
    "print (df_res.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   R\n",
      "G                                                   \n",
      "0  CREATE TABLE sandbox.yurbasov_count0_201801181...\n",
      "1  CREATE TABLE sandbox.yurbasov_count1_201801181...\n",
      "2  CREATE TABLE sandbox.yurbasov_count2_201801181...\n"
     ]
    }
   ],
   "source": [
    "df_query = df_res\n",
    "df_query['I'] = df_query.index\n",
    "df_query['R'] = df_query.apply(lambda row: \"CREATE TABLE sandbox.yurbasov_count\" + str(row['I']) + \"_201801181430\"\n",
    "                               + \" AS WITH c AS (select count(crd_no) as cnt, max(psg_date) as psg_date_,\"\n",
    "                               + \" crd_no as crd_no_\"\n",
    "                               + \" from metro_data.entries_db where crd_no in \" + str(row['V'])\n",
    "                               + \" group by crd_no), g AS (select a.psg_date, a.crd_no, a.pl_id,\"\n",
    "                               + \" lag(a.psg_date, 1) OVER (partition BY a.crd_no ORDER BY a.psg_date) AS psg_date_1,\"\n",
    "                               + \" lag(a.psg_date, 2) OVER (partition BY a.crd_no ORDER BY a.psg_date) AS psg_date_2,\"\n",
    "                               + \" lag(a.psg_date, 3) OVER (partition BY a.crd_no ORDER BY a.psg_date) AS psg_date_3,\"\n",
    "                               + \" lag(a.psg_date, 4) OVER (partition BY a.crd_no ORDER BY a.psg_date) AS psg_date_4,\"\n",
    "                               + \" lag(a.psg_date, 5) OVER (partition BY a.crd_no ORDER BY a.psg_date) AS psg_date_5,\"\n",
    "                               + \" lag(a.psg_date, 6) OVER (partition BY a.crd_no ORDER BY a.psg_date) AS psg_date_6,\"\n",
    "                               + \" lag(a.psg_date, 7) OVER (partition BY a.crd_no ORDER BY a.psg_date) AS psg_date_7,\"\n",
    "                               + \" lag(a.psg_date, 8) OVER (partition BY a.crd_no ORDER BY a.psg_date) AS psg_date_8,\"\n",
    "                               + \" lag(a.psg_date, 9) OVER (partition BY a.crd_no ORDER BY a.psg_date) AS psg_date_9,\"\n",
    "                               + \" lag(a.pl_id, 1) OVER (partition BY a.crd_no ORDER BY a.psg_date) AS pl_id_1,\"\n",
    "                               + \" lag(a.pl_id, 2) OVER (partition BY a.crd_no ORDER BY a.psg_date) AS pl_id_2,\"\n",
    "                               + \" lag(a.pl_id, 3) OVER (partition BY a.crd_no ORDER BY a.psg_date) AS pl_id_3,\"\n",
    "                               + \" lag(a.pl_id, 4) OVER (partition BY a.crd_no ORDER BY a.psg_date) AS pl_id_4,\"\n",
    "                               + \" lag(a.pl_id, 5) OVER (partition BY a.crd_no ORDER BY a.psg_date) AS pl_id_5,\"\n",
    "                               + \" lag(a.pl_id, 6) OVER (partition BY a.crd_no ORDER BY a.psg_date) AS pl_id_6,\"\n",
    "                               + \" lag(a.pl_id, 7) OVER (partition BY a.crd_no ORDER BY a.psg_date) AS pl_id_7,\"\n",
    "                               + \" lag(a.pl_id, 8) OVER (partition BY a.crd_no ORDER BY a.psg_date) AS pl_id_8,\"\n",
    "                               + \" lag(a.pl_id, 9) OVER (partition BY a.crd_no ORDER BY a.psg_date) AS pl_id_9\"\n",
    "                               + \" from metro_data.entries_db a)\"\n",
    "                               + \" select c.cnt as cnt, g.* from g\" \n",
    "                               + \" join c on c.crd_no_ = g.crd_no and c.psg_date_ = g.psg_date where cnt>2\", axis=1)\n",
    "df_query = df_query[['R']]\n",
    "print (df_query.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_query.to_csv(os.path.join(data_dir, 'hive.csv'), header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
