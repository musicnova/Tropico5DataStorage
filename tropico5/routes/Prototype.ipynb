{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "data_dir = '/home/user/DEPTRANS'\n",
    "\n",
    "import typing as tp\n",
    "# https://docs.python.org/3/library/typing.html\n",
    "def khd_cast(col, kind) -> tp.NewType:\n",
    "    return NewType('UserId', int)\n",
    "\n",
    "#    (col, kind) => (col, kind) match \n",
    "#    case (c, EKHD.Number) => c cast LongType\n",
    "#    case (c, EKHD.Number155) => c cast LongType\n",
    "#    case (c, EKHD.Number53) => c cast LongType\n",
    "#    case (c, EKHD.Number18) => c cast LongType\n",
    "#    case (c, EKHD.Number10) => c cast LongType\n",
    "#    case (c, EKHD.Number3) => c cast LongType\n",
    "#    case (c, EKHD.Date) => unix_timestamp(c, formatDate)\n",
    "#    case (c, EKHD.Timestamp) => unix_timestamp(c, formatTs)\n",
    "#    case (c, _) => c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Line LineColor         Name   Latitude  Longitude  Order\n",
      "0  Калининская    FFCD1C   Новокосино  55.745113  37.864052      0\n",
      "1  Калининская    FFCD1C  Новогиреево  55.752237  37.814587      1\n",
      "2  Калининская    FFCD1C       Перово  55.750980  37.784220      2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_inet_geo2_dicts = pd.read_csv(os.path.join(data_dir, 'temp_inet', 'metro_geo2.csv'), sep=',')\n",
    "print (df_inet_geo2_dicts.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  line_codes_csv.color  line_codes_csv.line_id        line_codes_csv.name\n",
      "0              #EF1E25                       1       Сокольническая линия\n",
      "1              #029A55                       2       Замоскворецкая линия\n",
      "2              #0252A2                       3  Арбатско-Покровская линия\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_troyka_lines = pd.read_csv(os.path.join(data_dir, 'temp_troyka', 'line_codes_csv.csv'), sep=',')\n",
    "print (df_troyka_lines.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   station_codes_csv.label_id  station_codes_csv.line_id  \\\n",
      "0                           1                          1   \n",
      "1                           1                          1   \n",
      "2                           2                          1   \n",
      "\n",
      "   station_codes_csv.link_id station_codes_csv.name  \\\n",
      "0                       1002  Бульвар Рокоссовского   \n",
      "1                       1229  Бульвар Рокоссовского   \n",
      "2                       1002           Черкизовская   \n",
      "\n",
      "   station_codes_csv.station_id  \n",
      "0                             1  \n",
      "1                             1  \n",
      "2                             2  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_troyka_stations = pd.read_csv(os.path.join(data_dir, 'temp_troyka', 'station_codes_csv.csv'), sep=',')\n",
    "print (df_troyka_stations.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   entrance_station_codes_csv.entrance_id  \\\n",
      "0                                      20   \n",
      "1                                      21   \n",
      "2                                      23   \n",
      "\n",
      "  entrance_station_codes_csv.entrance_name  \\\n",
      "0         Бульвар Рокоссовского (Северный)   \n",
      "1            Бульвар Рокоссовского (Южный)   \n",
      "2                  Черкизовская (Северный)   \n",
      "\n",
      "  entrance_station_codes_csv.station_name  \n",
      "0                   Бульвар Рокоссовского  \n",
      "1                   Бульвар Рокоссовского  \n",
      "2                            Черкизовская  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_troyka_entrance_stations = pd.read_csv(os.path.join(data_dir, 'temp_troyka', \n",
    "                                                       'entrance_station_codes_csv.csv'), sep=',')\n",
    "print (df_troyka_entrance_stations.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   LINE_NUMBER  STATION_NUMBER_ABS    STATION_NAME_LONG_RU  \\\n",
      "0            1                   1   Бульвар Рокоссовского   \n",
      "1            1                   2            Черкизовская   \n",
      "2            1                   3  Преображенская площадь   \n",
      "\n",
      "         STATION_NAME_LONG_EN  \n",
      "0        Bulvar Rokossovskogo  \n",
      "1              Cherkizovskaya  \n",
      "2  Preobrazhenskaya Ploshchad  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_maxima_20170615_dicts = pd.read_csv(os.path.join(data_dir, 'temp_maxima', '2017-06-15.csv'), sep=',')\n",
    "print (df_maxima_20170615_dicts.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label_id  station_id\n",
      "0         1           1\n",
      "1         1         229\n",
      "2         2           2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_yandex_label_codes01 = pd.read_csv(os.path.join(data_dir, 'temp_yandex', 'label_codes.csv'), sep=',')\n",
    "print (df_yandex_label_codes01.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     color  line_id                       name\n",
      "0  #EF1E25        1       Сокольническая линия\n",
      "1  #029A55        2       Замоскворецкая линия\n",
      "2  #0252A2        3  Арбатско-Покровская линия\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_yandex_line_codes02 = pd.read_csv(os.path.join(data_dir, 'temp_yandex', 'line_codes.csv'), sep=',')\n",
    "print (df_yandex_line_codes02.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label_id  line_id  link_id                   name  station_id\n",
      "0         1        1     1002  Бульвар Рокоссовского           1\n",
      "1         1        1     1229  Бульвар Рокоссовского           1\n",
      "2         2        1     1002           Черкизовская           2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_yandex_station_codes03 = pd.read_csv(os.path.join(data_dir, 'temp_yandex', 'station_codes.csv'), sep=',')\n",
    "print (df_yandex_station_codes03.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   from_station_id  link_id  time  to_station_id  transfer  transfer_id  \\\n",
      "0                1     1002   190              2         0          NaN   \n",
      "1                1     1229   541            229         1       1229.0   \n",
      "2                2     2003   145              3         0          NaN   \n",
      "\n",
      "       type  \n",
      "0      link  \n",
      "1  transfer  \n",
      "2      link  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_yandex_link_codes04 = pd.read_csv(os.path.join(data_dir, 'temp_yandex', 'link_codes.csv'), sep=',')\n",
    "print (df_yandex_link_codes04.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   station_id  transfer_id\n",
      "0         229         1229\n",
      "1           1         1229\n",
      "2         117         9117\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_yandex_transfer_codes05 = pd.read_csv(os.path.join(data_dir, 'temp_yandex', 'transfer_codes.csv'), sep=',')\n",
    "print (df_yandex_transfer_codes05.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   code                                description  id  schema\n",
      "0     1                   Пример (Юра, 11.12.2017)   1       0\n",
      "1     2  Матчинг Тройка и WiFi (Денис, 12.12.2017)   2       0\n",
      "   color  demo_time_m  id  key_point  key_records_id  link_type  linked_point  \\\n",
      "0      0          0.0   1          0               0          0             0   \n",
      "1      0          0.0   2          0               0          0             0   \n",
      "\n",
      "   linked_records_id  owners_schema  stats_sheet  \n",
      "0                  0              0            0  \n",
      "1                  0              0            0  \n",
      "   flags  from_key_point  graphs_id  id  number  owners_id  probability  \\\n",
      "0      0               1          0   1       1          0          1.0   \n",
      "1      0               2          0   2       1          0          1.0   \n",
      "\n",
      "   profiles_id  step  time_m  to_linked_point  \n",
      "0            0     1     0.0                2  \n",
      "1            0     2     0.0                1  \n",
      "      fio  id mobile_tel  owners_code\n",
      "0  A.A.A.   1        1-1            1\n",
      "1  B.B.B.   2        2-2            1\n",
      "   canvas_x  canvas_y en_door_name  geo_flags  geo_lat  geo_long  id  \\\n",
      "0       100       200            -          1     55.5      40.2   1   \n",
      "1       100       200            -          1     57.5      40.3   2   \n",
      "\n",
      "   owners_schema st_code  st_line_number st_maxima_code st_maxima_name_e  \\\n",
      "0              1     101               1            111          Maxima1   \n",
      "1              1     102               2            222          Maxima2   \n",
      "\n",
      "  st_maxima_name_r st_name_e st_name_r st_yandex_code st_yandex_name_e  \\\n",
      "0        Тестовая1         B         A           1111          Yandex1   \n",
      "1        Тестовая2         B         A           2222          Yandex2   \n",
      "\n",
      "  st_yandex_name_r  type  \n",
      "0          Яндекс1     0  \n",
      "1          Яндекс2     0  \n",
      "   avg_time_m  duration  graphs_id  id  resource_code1  resource_code2  \\\n",
      "0          90       900          0   1               1               2   \n",
      "1         100       900          0   2               1               2   \n",
      "\n",
      "   resource_type  sheet  ts  \n",
      "0             99      0   0  \n",
      "1             99      0   0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import enum as e\n",
    "\n",
    "class CaseOwnersCode(e.Enum):\n",
    "    EXAMPLE = 1\n",
    "    BYCICLES_WIFI_MATCH = 2\n",
    "    TROYKA_WIFI_MATCH = 3\n",
    "\n",
    "class CaseOwnersSchema(e.Enum):\n",
    "    DEFAULT_METRO_TRANSFERS_ENTRANCES = 1\n",
    "    \n",
    "class CaseGraphsLinkType(e.Enum):\n",
    "    METRO = 1\n",
    "    TRANSFER = 2\n",
    "    ENTRANCE = 3\n",
    "    #BADTRANSFER = 4\n",
    "    #FOOT = 5\n",
    "\n",
    "class CaseGraphsColor(e.Enum):\n",
    "    UNKNOWN = 0\n",
    "    HFF0000 = 1\n",
    "    H00FF00 = 2\n",
    "    H0000FF = 3\n",
    "\n",
    "class CaseStatsResourceType(e.Enum):\n",
    "    DEMO = 1\n",
    "    YANDEX_API = 2\n",
    "\n",
    "class CaseRecordsType(e.Enum):\n",
    "    ST = 1\n",
    "    EX = 2\n",
    "    EN = 3\n",
    "    #PA = 4\n",
    "\n",
    "d_case_owners = {'id': [1, 2], 'code': [1, 2], 'schema': [0, 0],\n",
    "                 'description': ['Пример (Юра, 11.12.2017)', 'Матчинг Тройка и WiFi (Денис, 12.12.2017)']}\n",
    "df_case_owners = pd.DataFrame(data=d_case_owners)\n",
    "print (df_case_owners)\n",
    "\n",
    "d_case_graphs = {'id': [1, 2], 'owners_schema': [0, 0], 'key_point': [0, 0], 'linked_point': [0, 0],\n",
    "                 'key_records_id': [0, 0], 'linked_records_id': [0, 0], 'stats_sheet': [0, 0],\n",
    "                 'demo_time_m': [0.0, 0.0],\n",
    "                 'link_type': [0, 0], 'color': [0, 0]}\n",
    "df_case_graphs = pd.DataFrame(data=d_case_graphs)\n",
    "print (df_case_graphs)\n",
    "\n",
    "d_case_routes = {'id': [1, 2], 'owners_id': [0, 0], 'number': [1, 1], 'profiles_id': [0, 0], 'step': [1, 2],\n",
    "                 'graphs_id': [0, 0],\n",
    "                 'from_key_point': [1, 2], 'to_linked_point': [2, 1],\n",
    "                 'flags': [0, 0], 'probability': [1.0, 1.0], 'time_m': [0.0, 0.0]}\n",
    "df_case_routes = pd.DataFrame(data=d_case_routes)\n",
    "print (df_case_routes)\n",
    "\n",
    "d_case_profiles = {'id': [1, 2], 'owners_code': [1, 1], 'mobile_tel': ['1-1', '2-2'],\n",
    "                 'fio': ['A.A.A.', 'B.B.B.']}\n",
    "df_case_profiles = pd.DataFrame(data=d_case_profiles)\n",
    "print (df_case_profiles)\n",
    "\n",
    "d_case_records = {'id': [1, 2], 'owners_schema': [1, 1], 'type': [0, 0], 'en_door_name': ['-', '-'],\n",
    "                  'st_line_number': [1, 2],\n",
    "                  'st_code': ['101', '102'], 'st_name_r': ['A', 'A'], 'st_name_e': ['B', 'B'],\n",
    "                  'st_maxima_code': ['111', '222'], 'st_maxima_name_r': ['Тестовая1', 'Тестовая2'],\n",
    "                  'st_maxima_name_e': ['Maxima1', 'Maxima2'],\n",
    "                  'st_yandex_code': ['1111', '2222'], 'st_yandex_name_r': ['Яндекс1', 'Яндекс2'],\n",
    "                  'st_yandex_name_e': ['Yandex1', 'Yandex2'], 'canvas_x': [100, 100], 'canvas_y': [200, 200],\n",
    "                  'geo_flags': [1, 1], 'geo_lat': [55.5, 57.5], 'geo_long': [40.2, 40.3]}\n",
    "df_case_records = pd.DataFrame(data=d_case_records)\n",
    "print (df_case_records)\n",
    "\n",
    "d_case_stats = {'id': [1, 2], 'graphs_id': [0, 0], 'sheet': [0, 0], 'resource_type': [99, 99],\n",
    "                       'resource_code1': [1, 1], 'resource_code2': [2, 2],\n",
    "                       'ts': [0, 0], 'duration': [15*60, 15*60], 'avg_time_m': [90, 100]}\n",
    "df_case_stats = pd.DataFrame(data=d_case_stats)\n",
    "print (df_case_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "right_lines_r\n",
      "   line_id                  line_name  new_line_id           short_name RIGHT\n",
      "0        1       Сокольническая линия            1       Сокольническая     +\n",
      "1        2       Замоскворецкая линия            2       Замоскворецкая     +\n",
      "2        3  Арбатско-Покровская линия            3  Арбатско-Покровская     +\n"
     ]
    }
   ],
   "source": [
    "# Словарь опечаток в названиях линий\n",
    "df_right_lines = df_troyka_lines[['line_codes_csv.line_id', 'line_codes_csv.name']].rename(\n",
    "    columns = {'line_codes_csv.line_id': 'line_id', 'line_codes_csv.name': 'line_name'})\n",
    "df_right_lines['new_line_id'] = df_right_lines.apply(lambda row: row['line_id'], axis = 1)\n",
    "df_right_lines['short_name'] = df_right_lines.apply(lambda row: row['line_name'][:-6], axis = 1)\n",
    "df_right_lines['RIGHT'] = df_right_lines.apply(lambda row: '+', axis = 1)\n",
    "print(\"right_lines_r\\n\" + str(df_right_lines.head(3)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "right_lines_r\n",
      "   line_id                  line_name  new_line_id           short_name RIGHT\n",
      "0        1       Сокольническая линия            1       Сокольническая     +\n",
      "1        2       Замоскворецкая линия            2       Замоскворецкая     +\n",
      "2        3  Арбатско-Покровская линия            3  Арбатско-Покровская     +\n"
     ]
    }
   ],
   "source": [
    "df_right_lines_r = df_troyka_lines[['line_codes_csv.line_id', 'line_codes_csv.name']].rename(\n",
    "    columns = {'line_codes_csv.line_id': 'line_id', 'line_codes_csv.name': 'line_name'})\n",
    "df_right_lines_r['new_line_id'] = df_right_lines_r.apply(lambda row: row['line_id'], axis = 1)\n",
    "df_right_lines_r['short_name'] = df_right_lines_r.apply(lambda row: row['line_name'][:-6], axis = 1)\n",
    "df_right_lines_r['RIGHT'] = df_right_lines_r.apply(lambda row: '+', axis = 1)\n",
    "print(\"right_lines_r\\n\" + str(df_right_lines_r.head(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxima_lines_r\n",
      "             SOURCE  WRONG RIGHT\n",
      "0    MAXIMA20170615      1     +\n",
      "195  MAXIMA20170615      1     +\n",
      "198  MAXIMA20170615      1     +\n"
     ]
    }
   ],
   "source": [
    "df_maxima_lines_r = pd.merge(df_maxima_20170615_dicts, df_right_lines, how='left',\n",
    "                             left_on='LINE_NUMBER', right_on='new_line_id').rename(\n",
    "    columns = {'LINE_NUMBER': 'WRONG'})\n",
    "df_maxima_lines_r['SOURCE'] = 'MAXIMA20170615'\n",
    "df_maxima_lines_r = df_maxima_lines_r[['SOURCE', 'WRONG', 'RIGHT']].sort_values(by = ['WRONG'])\n",
    "print(\"maxima_lines_r\\n\" + str(df_maxima_lines_r.head(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yandex_lines_r\n",
      "          SOURCE                      WRONG RIGHT\n",
      "2   YLINECODES02  Арбатско-Покровская линия     +\n",
      "11  YLINECODES02            Бутовская линия     +\n",
      "1   YLINECODES02       Замоскворецкая линия     +\n"
     ]
    }
   ],
   "source": [
    "df_yandex_lines_r = pd.merge(df_yandex_line_codes02, df_right_lines, how='left',\n",
    "                             left_on='line_id', right_on='new_line_id').rename(columns = {'name': 'WRONG'})\n",
    "df_yandex_lines_r['SOURCE'] = 'YLINECODES02'\n",
    "df_yandex_lines_r = df_yandex_lines_r[['SOURCE', 'WRONG', 'RIGHT']].sort_values(by = ['WRONG'])\n",
    "print(\"yandex_lines_r\\n\" + str(df_yandex_lines_r.head(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inet_lines_r\n",
      "       SOURCE                WRONG RIGHT\n",
      "90   INETGEO2  Арбатско-Покровская     +\n",
      "201  INETGEO2            Бутовская     +\n",
      "28   INETGEO2       Замоскворецкая     +\n"
     ]
    }
   ],
   "source": [
    "df_inet_lines_r = pd.merge(df_inet_geo2_dicts, df_right_lines_r, how='left',\n",
    "                             left_on='Line', right_on='short_name').rename(columns = {'Line': 'WRONG'})\n",
    "df_inet_lines_r['SOURCE'] = 'INETGEO2'\n",
    "df_inet_lines_r = df_inet_lines_r[['SOURCE', 'WRONG', 'RIGHT']].sort_values(by = ['WRONG']).drop_duplicates()\n",
    "print(\"inet_lines_r\\n\" + str(df_inet_lines_r.head(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check_lines\n",
      "Empty DataFrame\n",
      "Columns: [SOURCE, WRONG, RIGHT]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "df_check_lines = pd.concat([df_maxima_lines_r[df_maxima_lines_r['RIGHT'].isnull()],\n",
    "                            df_yandex_lines_r[df_yandex_lines_r['RIGHT'].isnull()]]).sort_values(by = ['WRONG'])\n",
    "print(\"check_lines\\n\" + str(df_check_lines.head(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check_lines_r\n",
      "       SOURCE                          WRONG RIGHT\n",
      "237  INETGEO2                      Монорельс   NaN\n",
      "203  INETGEO2  Московское центральное кольцо   NaN\n"
     ]
    }
   ],
   "source": [
    "df_check_lines_r = pd.concat([df_inet_lines_r[df_inet_lines_r['RIGHT'].isnull()]]).sort_values(by = ['WRONG'])\n",
    "print(\"check_lines_r\\n\" + str(df_check_lines_r.head(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "right_stations_r\n",
      "                    line_name  new_line_id      short_name RIGHT  station_id  \\\n",
      "line_id                                                                        \n",
      "1        Сокольническая линия            1  Сокольническая     +         1.0   \n",
      "1        Сокольническая линия            1  Сокольническая     +         1.0   \n",
      "1        Сокольническая линия            1  Сокольническая     +         2.0   \n",
      "\n",
      "                  station_name       new_station_name  \n",
      "line_id                                                \n",
      "1        Бульвар Рокоссовского  Бульвар Рокоссовского  \n",
      "1        Бульвар Рокоссовского  Бульвар Рокоссовского  \n",
      "1                 Черкизовская           Черкизовская  \n"
     ]
    }
   ],
   "source": [
    "# Словарь опечаток в названиях станций\n",
    "df_right_stations_r = df_right_lines_r.set_index('line_id').join(df_troyka_stations[['station_codes_csv.line_id',\n",
    "    'station_codes_csv.station_id', 'station_codes_csv.name']].rename(columns = {'station_codes_csv.line_id': 'line_id',\n",
    "    'station_codes_csv.station_id': 'station_id', 'station_codes_csv.name': 'station_name'}).set_index('line_id'),\n",
    "    how = 'left', rsuffix=\"station_\")\n",
    "df_right_stations_r['new_station_name'] = df_right_stations_r.apply(lambda row: row['station_name'], axis = 1)\n",
    "df_right_stations_r['RIGHT'] = df_right_stations_r.apply(lambda row: '+', axis = 1)\n",
    "print(\"right_stations_r\\n\" + str(df_right_stations_r.head(3)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df_maxima_stations_r = df_maxima_20170615_dicts[['STATION_NAME_LONG_RU']]\n",
    "#df_maxima_stations_r['SOURCE'] = 'MAXIMA20170615'\n",
    "#print(\"maxima_stations_r\\n\" + str(df_maxima_stations_r.head(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxima_stations_r\n",
      "             SOURCE          WRONG RIGHT\n",
      "473  MAXIMA20170615   Авиамоторная     +\n",
      "472  MAXIMA20170615   Авиамоторная     +\n",
      "93   MAXIMA20170615  Автозаводская     +\n"
     ]
    }
   ],
   "source": [
    "df_maxima_stations_r = pd.merge(df_maxima_20170615_dicts, df_right_stations_r, how='left',\n",
    "                             left_on='STATION_NAME_LONG_RU', right_on='new_station_name').rename(\n",
    "    columns = {'STATION_NAME_LONG_RU': 'WRONG'})\n",
    "df_maxima_stations_r['SOURCE'] = 'MAXIMA20170615'\n",
    "df_maxima_stations_r = df_maxima_stations_r[['SOURCE', 'WRONG', 'RIGHT']].sort_values(by = ['WRONG'])\n",
    "print(\"maxima_stations_r\\n\" + str(df_maxima_stations_r.head(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df_yandex_stations_r = df_yandex_station_codes03[['name']]\n",
    "#df_yandex_stations_r['SOURCE'] = 'YSTATIONCODES03'\n",
    "#print(\"yandex_stations_r\\n\" + str(df_yandex_stations_r.head(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yandex_stations_r\n",
      "               SOURCE         WRONG RIGHT\n",
      "1331  YSTATIONCODES03  Авиамоторная     +\n",
      "1333  YSTATIONCODES03  Авиамоторная     +\n",
      "1332  YSTATIONCODES03  Авиамоторная     +\n"
     ]
    }
   ],
   "source": [
    "df_yandex_stations_r = pd.merge(df_yandex_station_codes03, df_right_stations_r, how='left',\n",
    "                             left_on='name', right_on='new_station_name').rename(columns = {'name': 'WRONG'})\n",
    "df_yandex_stations_r['SOURCE'] = 'YSTATIONCODES03'\n",
    "df_yandex_stations_r = df_yandex_stations_r[['SOURCE', 'WRONG', 'RIGHT']].sort_values(by = ['WRONG'])\n",
    "print(\"yandex_stations_r\\n\" + str(df_yandex_stations_r.head(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inet_stations_r\n",
      "       SOURCE          WRONG RIGHT\n",
      "6    INETGEO2   Авиамоторная     +\n",
      "73   INETGEO2  Автозаводская     +\n",
      "152  INETGEO2  Академическая     +\n"
     ]
    }
   ],
   "source": [
    "df_inet_stations_r = pd.merge(df_inet_geo2_dicts, df_right_stations_r, how='left',\n",
    "                             left_on='Name', right_on='station_name').rename(columns = {'Name': 'WRONG'})\n",
    "df_inet_stations_r['SOURCE'] = 'INETGEO2'\n",
    "df_inet_stations_r = df_inet_stations_r[['SOURCE', 'WRONG', 'RIGHT']].sort_values(by = ['WRONG']).drop_duplicates()\n",
    "print(\"inet_stations_r\\n\" + str(df_inet_stations_r.head(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check_stations_r\n",
      "             SOURCE                     WRONG RIGHT\n",
      "196        INETGEO2      Библиотека им.Ленина   NaN\n",
      "613        INETGEO2           Битцевский Парк   NaN\n",
      "609  MAXIMA20170615  Бульвар адмирала Ушакова   NaN\n"
     ]
    }
   ],
   "source": [
    "df_check_stations_r = pd.concat([df_maxima_stations_r[df_maxima_stations_r['RIGHT'].isnull()],\n",
    "                            df_yandex_stations_r[df_yandex_stations_r['RIGHT'].isnull()],\n",
    "                            df_inet_stations_r[df_inet_stations_r['RIGHT'].isnull()]]).sort_values(by = ['WRONG'])\n",
    "print(\"check_stations_r\\n\" + str(df_check_stations_r.head(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [WRONG, RIGHT]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Подгрузка НСИ для названия линий\n",
    "import pandas as pd\n",
    "df_fix_name_lines_r = pd.read_csv(os.path.join(data_dir, 'temp_nsi', 'fix_name_lines_r.csv'), sep=';')\n",
    "print (df_fix_name_lines_r.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         WRONG,RIGHT\n",
      "0  Ѕульвар адмирала ”шакова,Бульвар адмирала Ушакова\n",
      "1                       расные ворота,Красные ворота\n",
      "2           ресть¤нска¤ застава,Крестьянская застава\n"
     ]
    }
   ],
   "source": [
    "# Подгрузка НСИ для названия станций\n",
    "import pandas as pd\n",
    "df_fix_name_stations_r = pd.read_csv(os.path.join(data_dir, 'temp_nsi', 'fix_name_stations_r.csv'), sep=';')\n",
    "print (df_fix_name_stations_r.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     CODE  MAXIMA_CODE\n",
      "204    14           -1\n",
      "203    13           -1\n",
      "21      1            1\n",
      "   line_codes_csv.color  line_codes_csv.line_id            line_codes_csv.name\n",
      "12              #9999FF                      13           Московский монорельс\n",
      "13              #FFA8AF                      14  Московское центральное кольцо\n"
     ]
    }
   ],
   "source": [
    "# Словарь соответствия линии MAXIMA\n",
    "df_maxima_lines_nsi = pd.merge( df_troyka_lines[['line_codes_csv.line_id']].rename(\n",
    "    columns = {'line_codes_csv.line_id': 'CODE'}), df_maxima_20170615_dicts[['LINE_NUMBER']].rename(\n",
    "    columns = {'LINE_NUMBER': 'MAXIMA_CODE'}), how='left', left_on='CODE', right_on='MAXIMA_CODE' )\n",
    "df_maxima_lines_nsi = df_maxima_lines_nsi.fillna(-1.0).sort_values(by = ['MAXIMA_CODE']).drop_duplicates()\n",
    "df_maxima_lines_nsi['MAXIMA_CODE'] = df_maxima_lines_nsi['MAXIMA_CODE'].astype(int)\n",
    "print (df_maxima_lines_nsi.head(3))\n",
    "\n",
    "# Отладка - что за линии 13 и 14\n",
    "print (df_troyka_lines[(df_troyka_lines['line_codes_csv.line_id'] == 13) | \n",
    "                       (df_troyka_lines['line_codes_csv.line_id'] == 14)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CODE  YANDEX_CODE\n",
      "0     1            1\n",
      "1     2            2\n",
      "2     3            3\n",
      "   line_codes_csv.color  line_codes_csv.line_id            line_codes_csv.name\n",
      "12              #9999FF                      13           Московский монорельс\n",
      "13              #FFA8AF                      14  Московское центральное кольцо\n"
     ]
    }
   ],
   "source": [
    "# Словарь соответствия линии YANDEX\n",
    "df_yandex_lines_nsi = pd.merge( df_troyka_lines[['line_codes_csv.line_id']].rename(\n",
    "    columns = {'line_codes_csv.line_id': 'CODE'}), df_yandex_line_codes02[['line_id']].rename(\n",
    "    columns = {'line_id': 'YANDEX_CODE'}), how='left', left_on='CODE', right_on='YANDEX_CODE' )\n",
    "df_yandex_lines_nsi = df_yandex_lines_nsi.fillna(-1).sort_values(by = ['YANDEX_CODE']).drop_duplicates()\n",
    "df_yandex_lines_nsi['YANDEX_CODE'] = df_yandex_lines_nsi['YANDEX_CODE'].astype(int)\n",
    "print (df_yandex_lines_nsi.head(3))\n",
    "\n",
    "# Отладка - что за линии 13 и 14\n",
    "print (df_troyka_lines[(df_troyka_lines['line_codes_csv.line_id'] == 13) | \n",
    "                       (df_troyka_lines['line_codes_csv.line_id'] == 14)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              NAME            INET_NAME\n",
      "204  Московское центральное кольцо               (null)\n",
      "203           Московский монорельс               (null)\n",
      "44       Арбатско-Покровская линия  Арбатско-Покровская\n",
      "   line_codes_csv.color  line_codes_csv.line_id  \\\n",
      "12              #9999FF                      13   \n",
      "13              #FFA8AF                      14   \n",
      "\n",
      "              line_codes_csv.name               short_name  \n",
      "12           Московский монорельс           Московский мон  \n",
      "13  Московское центральное кольцо  Московское центральное   \n"
     ]
    }
   ],
   "source": [
    "# Словарь соответствия линии INET\n",
    "df_troyka_lines_inet_fix = df_troyka_lines\n",
    "df_troyka_lines_inet_fix['short_name'] = df_troyka_lines_inet_fix.apply(lambda row:\n",
    "                                                                        row['line_codes_csv.name'][:-6], axis = 1)\n",
    "\n",
    "df_inet_lines_nsi = pd.merge( df_troyka_lines_inet_fix[['line_codes_csv.name', 'short_name']].rename(\n",
    "    columns = {'line_codes_csv.name': 'NAME'}), df_inet_geo2_dicts[['Line']].rename(\n",
    "    columns = {'Line': 'INET_NAME'}), how='left', left_on='short_name', right_on='INET_NAME' )\n",
    "df_inet_lines_nsi = df_inet_lines_nsi[['NAME', 'INET_NAME']]\n",
    "df_inet_lines_nsi = df_inet_lines_nsi.fillna('(null)').sort_values(by = ['INET_NAME']).drop_duplicates()\n",
    "print (df_inet_lines_nsi.head(3))\n",
    "\n",
    "# Отладка - что за линии 13 и 14\n",
    "print (df_troyka_lines[(df_troyka_lines['line_codes_csv.line_id'] == 13) | \n",
    "                       (df_troyka_lines['line_codes_csv.line_id'] == 14)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SOURCE                   RIGHT                   WRONG\n",
      "0       1   Бульвар Рокоссовского   Бульвар Рокоссовского\n",
      "1       2            Черкизовская            Черкизовская\n",
      "2       3  Преображенская площадь  Преображенская площадь\n",
      "   CODE  CODE_LINE                   NAME  MAXIMA_CODE_LINE  MAXIMA_CODE  \\\n",
      "0     1          1  Бульвар Рокоссовского                 1            1   \n",
      "1     1          1  Бульвар Рокоссовского                 1            2   \n",
      "2     1          1  Бульвар Рокоссовского                 1            3   \n",
      "\n",
      "              MAXIMA_NAME                   RIGHT SOURCE  \\\n",
      "0   Бульвар Рокоссовского   Бульвар Рокоссовского      1   \n",
      "1            Черкизовская            Черкизовская      2   \n",
      "2  Преображенская площадь  Преображенская площадь      3   \n",
      "\n",
      "                    WRONG  \n",
      "0   Бульвар Рокоссовского  \n",
      "1            Черкизовская  \n",
      "2  Преображенская площадь  \n",
      "    CODE  MAXIMA_CODE  CODE_LINE  MAXIMA_CODE_LINE\n",
      "0      1            1          1                 1\n",
      "34     1            1          1                 1\n",
      "69     2            2          1                 1\n",
      "     CODE  MAXIMA_CODE  CODE_LINE  MAXIMA_CODE_LINE\n",
      "0       1            1          1                 1\n",
      "69      2            2          1                 1\n",
      "172     3            3          1                 1\n",
      "   line_codes_csv.color  line_codes_csv.line_id  \\\n",
      "12              #9999FF                      13   \n",
      "13              #FFA8AF                      14   \n",
      "\n",
      "              line_codes_csv.name               short_name  \n",
      "12           Московский монорельс           Московский мон  \n",
      "13  Московское центральное кольцо  Московское центральное   \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Словарь соответствия станции MAXIMA\n",
    "df_dummy_stations_maxima = pd.merge(df_maxima_20170615_dicts[['STATION_NUMBER_ABS', 'STATION_NAME_LONG_RU']].rename(\n",
    "    columns = {'STATION_NUMBER_ABS': 'SOURCE', 'STATION_NAME_LONG_RU': 'RIGHT'}),\n",
    "                               df_maxima_20170615_dicts[['STATION_NAME_LONG_RU']].rename(\n",
    "    columns = {'STATION_NAME_LONG_RU': 'WRONG'}), left_on='RIGHT', right_on='WRONG')\n",
    "df_dummy_stations_maxima = df_dummy_stations_maxima[['SOURCE', 'RIGHT', 'WRONG']]\n",
    "print (df_dummy_stations_maxima.head(3))\n",
    "\n",
    "df_maxima_stations_nsi = pd.merge( df_troyka_stations[['station_codes_csv.station_id',\n",
    "             'station_codes_csv.line_id', 'station_codes_csv.name']].rename(\n",
    "    columns = {'station_codes_csv.station_id': 'CODE', 'station_codes_csv.line_id': 'CODE_LINE',\n",
    "              'station_codes_csv.name': 'NAME'}),\n",
    "                                  df_maxima_20170615_dicts[['LINE_NUMBER', 'STATION_NUMBER_ABS',\n",
    "                                                           'STATION_NAME_LONG_RU']].rename(\n",
    "    columns = {'LINE_NUMBER': 'MAXIMA_CODE_LINE', 'STATION_NUMBER_ABS': 'MAXIMA_CODE',\n",
    "              'STATION_NAME_LONG_RU': 'MAXIMA_NAME'}),\n",
    "                                  how='left', left_on='CODE_LINE', right_on='MAXIMA_CODE_LINE')\n",
    "df_maxima_stations_nsi = df_maxima_stations_nsi.fillna(-1.0)\n",
    "df_maxima_stations_nsi['MAXIMA_CODE'] = df_maxima_stations_nsi['MAXIMA_CODE'].astype(int)\n",
    "df_maxima_stations_nsi['MAXIMA_CODE_LINE'] = df_maxima_stations_nsi['MAXIMA_CODE_LINE'].astype(int)\n",
    "df_maxima_stations_nsi = pd.merge( df_maxima_stations_nsi, pd.concat( [df_check_stations_r,\n",
    "                     df_dummy_stations_maxima] ), how='left', left_on='MAXIMA_NAME', right_on='WRONG' )\n",
    "print (df_maxima_stations_nsi.head(3))\n",
    "\n",
    "df_maxima_stations_nsi = df_maxima_stations_nsi[(df_maxima_stations_nsi['NAME'] == df_maxima_stations_nsi['RIGHT'])]\n",
    "df_maxima_stations_nsi = df_maxima_stations_nsi[['CODE', 'MAXIMA_CODE', \n",
    "                                                'CODE_LINE', 'MAXIMA_CODE_LINE']]\n",
    "print (df_maxima_stations_nsi.head(3))\n",
    "\n",
    "df_maxima_stations_nsi = df_maxima_stations_nsi.drop_duplicates()\n",
    "df_maxima_stations_nsi = df_maxima_stations_nsi.sort_values(by = ['MAXIMA_CODE'])\n",
    "print (df_maxima_stations_nsi.head(3))\n",
    "\n",
    "# Отладка - что за линии 13 и 14\n",
    "print (df_troyka_lines[(df_troyka_lines['line_codes_csv.line_id'] == 13) | \n",
    "                       (df_troyka_lines['line_codes_csv.line_id'] == 14)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SOURCE                  RIGHT                  WRONG\n",
      "0       1  Бульвар Рокоссовского  Бульвар Рокоссовского\n",
      "1       1  Бульвар Рокоссовского  Бульвар Рокоссовского\n",
      "2       1  Бульвар Рокоссовского  Бульвар Рокоссовского\n",
      "   CODE  CODE_LINE                   NAME  label_id  YANDEX_CODE_LINE_NEW  \\\n",
      "0     1          1  Бульвар Рокоссовского         1                     1   \n",
      "1     1          1  Бульвар Рокоссовского         1                     1   \n",
      "2     1          1  Бульвар Рокоссовского         1                     1   \n",
      "\n",
      "   link_id            YANDEX_NAME  YANDEX_CODE  YANDEX_CODE_LINE  \\\n",
      "0     1002  Бульвар Рокоссовского            1                 1   \n",
      "1     1002  Бульвар Рокоссовского            1                 1   \n",
      "2     1002  Бульвар Рокоссовского            1                 1   \n",
      "\n",
      "                   RIGHT SOURCE                  WRONG  \n",
      "0  Бульвар Рокоссовского      1  Бульвар Рокоссовского  \n",
      "1  Бульвар Рокоссовского      1  Бульвар Рокоссовского  \n",
      "2  Бульвар Рокоссовского      1  Бульвар Рокоссовского  \n",
      "   CODE  YANDEX_CODE  CODE_LINE  YANDEX_CODE_LINE\n",
      "0     1            1          1                 1\n",
      "1     1            1          1                 1\n",
      "2     1            1          1                 1\n",
      "      CODE  YANDEX_CODE  CODE_LINE  YANDEX_CODE_LINE\n",
      "0        1            1          1                 1\n",
      "1370     2            2          1                 1\n",
      "3377     3            3          1                 1\n",
      "   line_codes_csv.color  line_codes_csv.line_id  \\\n",
      "12              #9999FF                      13   \n",
      "13              #FFA8AF                      14   \n",
      "\n",
      "              line_codes_csv.name               short_name  \n",
      "12           Московский монорельс           Московский мон  \n",
      "13  Московское центральное кольцо  Московское центральное   \n"
     ]
    }
   ],
   "source": [
    "# Словарь соответствия станции YANDEX\n",
    "df_dummy_stations_yandex = pd.merge(df_yandex_station_codes03[['station_id', 'name']].rename(\n",
    "    columns = {'station_id': 'SOURCE', 'name': 'RIGHT'}),\n",
    "             df_yandex_station_codes03[['name']].rename(\n",
    "    columns = {'name': 'WRONG'}), left_on='RIGHT', right_on='WRONG')\n",
    "df_dummy_stations_yandex = df_dummy_stations_yandex[['SOURCE', 'RIGHT', 'WRONG']]\n",
    "print (df_dummy_stations_yandex.head(3))\n",
    "\n",
    "df_yandex_stations_nsi = pd.merge( df_troyka_stations[['station_codes_csv.station_id',\n",
    "             'station_codes_csv.line_id', 'station_codes_csv.name']].rename(\n",
    "    columns = {'station_codes_csv.station_id': 'CODE', 'station_codes_csv.line_id': 'CODE_LINE',\n",
    "              'station_codes_csv.name': 'NAME'}), pd.merge(df_yandex_station_codes03.rename(\n",
    "    columns = {'line_id': 'YANDEX_CODE_LINE_NEW', 'station_id': 'YANDEX_CODE', 'name': 'YANDEX_NAME'}),\n",
    "        df_yandex_line_codes02[['line_id']].rename(\n",
    "    columns = {'line_id': 'YANDEX_CODE_LINE'}), how='left', left_on='YANDEX_CODE_LINE_NEW',\n",
    "        right_on='YANDEX_CODE_LINE' ), how='left', left_on='CODE_LINE', right_on='YANDEX_CODE_LINE' )\n",
    "df_yandex_stations_nsi = df_yandex_stations_nsi.fillna(-1.0)\n",
    "df_yandex_stations_nsi['YANDEX_CODE'] = df_yandex_stations_nsi['YANDEX_CODE'].astype(int)\n",
    "df_yandex_stations_nsi['YANDEX_CODE_LINE'] = df_yandex_stations_nsi['YANDEX_CODE_LINE'].astype(int)\n",
    "df_yandex_stations_nsi = pd.merge( df_yandex_stations_nsi, pd.concat( [df_check_stations_r,\n",
    "                     df_dummy_stations_yandex] ), how='left', left_on='YANDEX_NAME', right_on='WRONG' )\n",
    "print (df_yandex_stations_nsi.head(3))\n",
    "\n",
    "df_yandex_stations_nsi = df_yandex_stations_nsi[(df_yandex_stations_nsi['NAME'] == df_yandex_stations_nsi['RIGHT'])]\n",
    "df_yandex_stations_nsi = df_yandex_stations_nsi[['CODE', 'YANDEX_CODE',\n",
    "                                                'CODE_LINE', 'YANDEX_CODE_LINE']]\n",
    "print (df_yandex_stations_nsi.head(3))\n",
    "\n",
    "df_yandex_stations_nsi = df_yandex_stations_nsi.drop_duplicates()\n",
    "df_yandex_stations_nsi = df_yandex_stations_nsi.sort_values(by = ['YANDEX_CODE'])\n",
    "print (df_yandex_stations_nsi.head(3))\n",
    "\n",
    "# Отладка - что за линии 13 и 14\n",
    "print (df_troyka_lines[(df_troyka_lines['line_codes_csv.line_id'] == 13) | \n",
    "                       (df_troyka_lines['line_codes_csv.line_id'] == 14)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        SOURCE        RIGHT        WRONG\n",
      "0  Калининская   Новокосино   Новокосино\n",
      "1  Калининская  Новогиреево  Новогиреево\n",
      "2  Калининская       Перово       Перово\n",
      "   CODE  CODE_LINE                   NAME  CODE_LINE_EXTRA  \\\n",
      "0     1          1  Бульвар Рокоссовского                1   \n",
      "1     1          1  Бульвар Рокоссовского                1   \n",
      "2     2          1           Черкизовская                1   \n",
      "\n",
      "              NAME_LINE INET_NAME_LINE_NEW LineColor INET_NAME  Latitude  \\\n",
      "0  Сокольническая линия                 -1        -1        -1      -1.0   \n",
      "1  Сокольническая линия                 -1        -1        -1      -1.0   \n",
      "2  Сокольническая линия                 -1        -1        -1      -1.0   \n",
      "\n",
      "   Longitude  Order INET_NAME_LINE RIGHT SOURCE WRONG  \n",
      "0       -1.0   -1.0             -1   NaN    NaN   NaN  \n",
      "1       -1.0   -1.0             -1   NaN    NaN   NaN  \n",
      "2       -1.0   -1.0             -1   NaN    NaN   NaN  \n",
      "     CODE              NAME         INET_NAME  CODE_LINE  \\\n",
      "644   201  Ботанический сад  Ботанический сад         14   \n",
      "645   201  Ботанический сад  Ботанический сад         14   \n",
      "646   201  Ботанический сад  Ботанический сад         14   \n",
      "\n",
      "                         NAME_LINE                 INET_NAME_LINE  \n",
      "644  Московское центральное кольцо  Московское центральное кольцо  \n",
      "645  Московское центральное кольцо  Московское центральное кольцо  \n",
      "646  Московское центральное кольцо  Московское центральное кольцо  \n",
      "       CODE           NAME      INET_NAME  CODE_LINE  \\\n",
      "78361   219  Автозаводская  Автозаводская         14   \n",
      "98201   224     Андроновка     Андроновка         14   \n",
      "22158   206     Балтийская     Балтийская         14   \n",
      "\n",
      "                           NAME_LINE                 INET_NAME_LINE  \n",
      "78361  Московское центральное кольцо  Московское центральное кольцо  \n",
      "98201  Московское центральное кольцо  Московское центральное кольцо  \n",
      "22158  Московское центральное кольцо  Московское центральное кольцо  \n",
      "   line_codes_csv.color  line_codes_csv.line_id  \\\n",
      "12              #9999FF                      13   \n",
      "13              #FFA8AF                      14   \n",
      "\n",
      "              line_codes_csv.name               short_name  \n",
      "12           Московский монорельс           Московский мон  \n",
      "13  Московское центральное кольцо  Московское центральное   \n"
     ]
    }
   ],
   "source": [
    "# Словарь соответствия станции INET\n",
    "df_dummy_stations_inet = pd.merge(df_inet_geo2_dicts[['Name', 'Line']].rename(\n",
    "    columns = {'Line': 'SOURCE', 'Name': 'RIGHT'}),\n",
    "             df_inet_geo2_dicts[['Name']].rename(\n",
    "    columns = {'Name': 'WRONG'}), left_on='RIGHT', right_on='WRONG')\n",
    "df_dummy_stations_inet = df_dummy_stations_inet[['SOURCE', 'RIGHT', 'WRONG']]\n",
    "print (df_dummy_stations_inet.head(3))\n",
    "\n",
    "df_inet_stations_nsi = pd.merge( pd.merge(df_troyka_stations[['station_codes_csv.station_id',\n",
    "             'station_codes_csv.line_id', 'station_codes_csv.name']].rename(\n",
    "    columns = {'station_codes_csv.station_id': 'CODE', 'station_codes_csv.line_id': 'CODE_LINE',\n",
    "              'station_codes_csv.name': 'NAME'}), df_troyka_lines[['line_codes_csv.line_id',\n",
    "         'line_codes_csv.name']].rename(columns = {'line_codes_csv.line_id': 'CODE_LINE_EXTRA',\n",
    "                                                  'line_codes_csv.name': 'NAME_LINE'}),\n",
    "                left_on='CODE_LINE', right_on='CODE_LINE_EXTRA', how='left'),\n",
    "    pd.merge(df_inet_geo2_dicts.rename(\n",
    "      columns = {'Line': 'INET_NAME_LINE_NEW', 'Name': 'INET_NAME'}),\n",
    "        df_inet_geo2_dicts[['Line']].rename(\n",
    "      columns = {'Line': 'INET_NAME_LINE'}), how='left', left_on='INET_NAME_LINE_NEW',\n",
    "        right_on='INET_NAME_LINE' ), how='left', left_on='NAME_LINE', right_on='INET_NAME_LINE' )\n",
    "df_inet_stations_nsi = df_inet_stations_nsi.fillna(-1.0)\n",
    "#df_inet_stations_nsi['INET_CODE'] = df_inet_stations_nsi['INET_CODE'].astype(int)\n",
    "#df_inet_stations_nsi['INET_CODE_LINE'] = df_inet_stations_nsi['INET_CODE_LINE'].astype(int)\n",
    "df_inet_stations_nsi = pd.merge( df_inet_stations_nsi, pd.concat( [df_check_stations_r,\n",
    "                     df_dummy_stations_inet] ), how='left', left_on='INET_NAME', right_on='WRONG' )\n",
    "print (df_inet_stations_nsi.head(3))\n",
    "\n",
    "df_inet_stations_nsi = df_inet_stations_nsi[(df_inet_stations_nsi['NAME'] == df_inet_stations_nsi['RIGHT'])]\n",
    "df_inet_stations_nsi = df_inet_stations_nsi[['CODE', 'NAME', 'INET_NAME',\n",
    "                                             'CODE_LINE', 'NAME_LINE', 'INET_NAME_LINE']]\n",
    "print (df_inet_stations_nsi.head(3))\n",
    "\n",
    "df_inet_stations_nsi = df_inet_stations_nsi.drop_duplicates()\n",
    "df_inet_stations_nsi = df_inet_stations_nsi.sort_values(by = ['INET_NAME'])\n",
    "print (df_inet_stations_nsi.head(3))\n",
    "\n",
    "# Отладка - что за линии 13 и 14\n",
    "print (df_troyka_lines[(df_troyka_lines['line_codes_csv.line_id'] == 13) | \n",
    "                       (df_troyka_lines['line_codes_csv.line_id'] == 14)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   flags  from_key_point  graphs_id  id  number  owners_id  probability  \\\n",
      "0      0               1          0   1       1          0          1.0   \n",
      "1      0               2          0   2       1          0          1.0   \n",
      "\n",
      "   profiles_id  step  time_m  to_linked_point  \n",
      "0            0     1     0.0                2  \n",
      "1            0     2     0.0                1  \n"
     ]
    }
   ],
   "source": [
    "def step01_make_case_owners(code, description):\n",
    "    # OK\n",
    "    d_examples = {'id': [101], 'code': [code], 'schema': [CaseOwnersSchema.DEFAULT_METRO_TRANSFERS_ENTRANCES],\n",
    "                 'description': [description]}\n",
    "    return pd.DataFrame(data=d_examples)\n",
    "\n",
    "# Шаг1/A.\n",
    "df_case_owners = step01_make_case_owners(CaseOwnersCode.EXAMPLE, 'Пример (Автор, 11.12.2017)')\n",
    "\n",
    "print (df_case_routes.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> df_step02a_troyka:\n",
      "   ST_CODE              ST_NAME_R  ST_LINE_NUMBER  ID  OWNERS_SCHEMA TYPE  \\\n",
      "0        1  Бульвар Рокоссовского               1   0              0   ST   \n",
      "1        1  Бульвар Рокоссовского               1   0              0   ST   \n",
      "2        2           Черкизовская               1   0              0   ST   \n",
      "\n",
      "  ST_NAME_E  \n",
      "0    (null)  \n",
      "1    (null)  \n",
      "2    (null)  \n",
      "> df_step02b_inet:\n",
      "    ID  OWNERS_SCHEMA TYPE  ST_LINE_NUMBER  ST_CODE ST_NAME_E  \\\n",
      "2    0              0   ST              14      201    (null)   \n",
      "33   0              0   ST              14      201    (null)   \n",
      "64   0              0   ST              14      201    (null)   \n",
      "\n",
      "           ST_NAME_R  GEO_FLAGS    GEO_LAT   GEO_LONG  \n",
      "2   Ботанический сад          0  55.845556  37.640278  \n",
      "33  Ботанический сад          0  55.845556  37.640278  \n",
      "64  Ботанический сад          0  55.845556  37.640278  \n",
      "> df_maxima_stations_nsi:\n",
      "     CODE  MAXIMA_CODE  CODE_LINE  MAXIMA_CODE_LINE\n",
      "0       1            1          1                 1\n",
      "69      2            2          1                 1\n",
      "172     3            3          1                 1\n",
      "> df_step02c_maxima:\n",
      "    ID  OWNERS_SCHEMA TYPE  ST_LINE_NUMBER  ST_CODE ST_NAME_E      ST_NAME_R  \\\n",
      "43   0              0   ST              14      219    (null)  Автозаводская   \n",
      "44   0              0   ST              14      219    (null)  Автозаводская   \n",
      "45   0              0   ST              14      219    (null)  Автозаводская   \n",
      "\n",
      "    GEO_FLAGS   GEO_LAT  GEO_LONG  CODE  ST_MAXIMA_CODE  CODE_LINE  \\\n",
      "43          0  55.70631  37.66314   NaN             NaN        NaN   \n",
      "44          0  55.70631  37.66314   NaN             NaN        NaN   \n",
      "45          0  55.70631  37.66314   NaN             NaN        NaN   \n",
      "\n",
      "    ST_MAXIMA_CODE_LINE  \n",
      "43                  NaN  \n",
      "44                  NaN  \n",
      "45                  NaN  \n",
      "   canvas_x  canvas_y en_door_name  geo_flags  geo_lat  geo_long    id  \\\n",
      "0       100       200            -          1     55.5      40.2  None   \n",
      "1       100       200            -          1     57.5      40.3  None   \n",
      "\n",
      "   owners_schema st_code  st_line_number st_maxima_code st_maxima_name_e  \\\n",
      "0              1     101               1            111          Maxima1   \n",
      "1              1     102               2            222          Maxima2   \n",
      "\n",
      "  st_maxima_name_r st_name_e st_name_r st_yandex_code st_yandex_name_e  \\\n",
      "0        Тестовая1         B         A           1111          Yandex1   \n",
      "1        Тестовая2         B         A           2222          Yandex2   \n",
      "\n",
      "  st_yandex_name_r  type  \n",
      "0          Яндекс1     0  \n",
      "1          Яндекс2     0  \n"
     ]
    }
   ],
   "source": [
    "def step02_make_case_records(schema, df_inet_geo2, df_troyka_lines, df_troyka_stations, df_troyka_entrances,\n",
    "                             df_maxima00, df_ylabel_codes01, df_yline_codes02, df_ystation_codes03,\n",
    "                             df_ylink_codes04, df_ytransfer_codes05):\n",
    "    # TODO\n",
    "    d_examples = {'id': [None, None], 'owners_schema': [schema, schema], 'type': [0, 0], 'en_door_name': ['-', '-'],\n",
    "                  'st_line_number': [1, 2],\n",
    "                  'st_code': ['101', '102'], 'st_name_r': ['A', 'A'], 'st_name_e': ['B', 'B'],\n",
    "                  'st_maxima_code': ['111', '222'], 'st_maxima_name_r': ['Тестовая1', 'Тестовая2'],\n",
    "                  'st_maxima_name_e': ['Maxima1', 'Maxima2'],\n",
    "                  'st_yandex_code': ['1111', '2222'], 'st_yandex_name_r': ['Яндекс1', 'Яндекс2'],\n",
    "                  'st_yandex_name_e': ['Yandex1', 'Yandex2'], 'canvas_x': [100, 100], 'canvas_y': [200, 200],\n",
    "                  'geo_flags': [1, 1], 'geo_lat': [55.5, 57.5], 'geo_long': [40.2, 40.3]}\n",
    "    return pd.DataFrame(data=d_examples)\n",
    "\n",
    "    #print(\"inet_geo2\\n\" + str(df_inet_geo2.head(3)))\n",
    "    #print(\"troyka_lines\\n\" + str(df_troyka_lines.head(3)))\n",
    "    #print(\"troyka_stations\\n\" + str(df_troyka_stations.head(3)))\n",
    "    #print(\"troyka_entrances\\n\" + str(df_troyka_entrances.head(3)))\n",
    "    #print(\"maxima00\\n\" + str(df_maxima00.head(3)))\n",
    "    #print(\"ylabel_codes01\\n\" + str(df_ylabel_codes01.head(3)))\n",
    "    #print(\"yline_codes02\\n\" + str(df_yline_codes02.head(3)))\n",
    "    #print(\"ystation_codes03\\n\" + str(df_ystation_codes03.head(3)))\n",
    "    #print(\"ylink_codes04\\n\" + str(df_ylink_codes04.head(3)))\n",
    "    #print(\"ytransfer_codes05\\n\" + str(df_ytransfer_codes05.head(3)))\n",
    "\n",
    "df_case_records = step02_make_case_records(1,\n",
    "    df_inet_geo2_dicts, df_troyka_lines, df_troyka_stations, df_troyka_entrance_stations,\n",
    "    df_maxima_20170615_dicts, df_yandex_label_codes01, df_yandex_line_codes02, df_yandex_station_codes03,\n",
    "    df_yandex_link_codes04, df_yandex_transfer_codes05)\n",
    "print (df_case_records.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    # Шаг2/A. Взять troyka и составить список code -> line_number, добавить тип ST\n",
    "    df_step02a_troyka = df_troyka_stations[['station_codes_csv.station_id', 'station_codes_csv.name',\n",
    "                                            'station_codes_csv.line_id']].rename(\n",
    "    columns = {'station_codes_csv.station_id': 'ST_CODE', 'station_codes_csv.name': 'ST_NAME_R',\n",
    "               'station_codes_csv.line_id': 'ST_LINE_NUMBER'})\n",
    "    df_step02a_troyka['ID'] = 0\n",
    "    df_step02a_troyka['OWNERS_SCHEMA'] = 0\n",
    "    df_step02a_troyka['TYPE'] = 'ST'\n",
    "    df_step02a_troyka['ST_NAME_E'] = '(null)'\n",
    "    print(\"> df_step02a_troyka:\\n\" + str(df_step02a_troyka.head(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    # Шаг2/B. Подтянуть inet\n",
    "    df_step02b_inet = pd.merge( df_step02a_troyka, df_inet_stations_nsi, how='left',\n",
    "                               left_on='ST_NAME_R', right_on='INET_NAME' ).rename(\n",
    "        columns = {'INET_NAME': 'ST_INET_NAME_R', 'INET_NAME_LINE': 'ST_INET_NAME_LINE_R'})\n",
    "    df_step02b_inet = df_step02b_inet[(df_step02b_inet['CODE_LINE'] == df_step02b_inet['ST_LINE_NUMBER'])]\n",
    "    df_step02b_inet = df_step02b_inet[['ID', 'OWNERS_SCHEMA', 'TYPE', 'ST_LINE_NUMBER',\n",
    "                                      'ST_CODE', 'ST_NAME_E',\n",
    "                                       'ST_NAME_R', 'ST_INET_NAME_R', 'ST_INET_NAME_LINE_R']]\n",
    "    # print(\"> __df_step02b_inet:\\n\" + str(df_step02b_inet.head(3)))\n",
    "    df_step02b_inet = pd.merge(df_step02b_inet, df_inet_geo2_dicts, how='left',\n",
    "                               left_on='ST_INET_NAME_LINE_R', right_on='Line')\n",
    "    df_step02b_inet = df_step02b_inet[(df_step02b_inet['ST_INET_NAME_R'] == df_step02b_inet['Name'])].rename(\n",
    "        columns={'Latitude': 'GEO_LAT', 'Longitude': 'GEO_LONG'})\n",
    "    df_step02b_inet['GEO_FLAGS'] = 0\n",
    "    # print(\"> _df_step02b_inet:\\n\" + str(df_step02b_inet.head(3)))\n",
    "    df_step02b_inet = df_step02b_inet[['ID', 'OWNERS_SCHEMA', 'TYPE', 'ST_LINE_NUMBER',\n",
    "                                       'ST_CODE', 'ST_NAME_E',\n",
    "                                       'ST_NAME_R', 'GEO_FLAGS', 'GEO_LAT', 'GEO_LONG']]\n",
    "    print(\"> df_step02b_inet:\\n\" + str(df_step02b_inet.head(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    # Шаг2/C. Подтянуть maxima\n",
    "    print(\"> df_maxima_stations_nsi:\\n\" + str(df_maxima_stations_nsi.head(3)))\n",
    "    df_step02c_maxima = pd.merge( df_step02b_inet, df_maxima_stations_nsi,\n",
    "                                 how='left', left_on='ST_CODE', right_on='CODE' ).rename(\n",
    "        columns = {'MAXIMA_CODE': 'ST_MAXIMA_CODE', 'MAXIMA_CODE_LINE': 'ST_MAXIMA_CODE_LINE'}).sort_values(\n",
    "        by = 'ST_NAME_R')\n",
    "    print(\"> df_step02c_maxima:\\n\" + str(df_step02c_maxima.head(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    # Шаг2/D. Подтянуть yandex\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   color  demo_time_m    id  key_point  key_records_id  link_type  \\\n",
      "1      0          0.0     1          0               0          0   \n",
      "2      0          0.0     2          0               0          0   \n",
      "0      0          0.0  None          0               0          0   \n",
      "1      0          0.0  None          0               0          0   \n",
      "\n",
      "   linked_point  linked_records_id  owners_schema  stats_sheet  \n",
      "1             0                  0              0            0  \n",
      "2             0                  0              0            0  \n",
      "0             0                  0              0            0  \n",
      "1             0                  0              0            0  \n"
     ]
    }
   ],
   "source": [
    "def step03_make_case_graphs(schema, df_records, df_inet_geo2, df_troyka_lines, df_troyka_stations, df_troyka_entrances,\n",
    "                            df_maxima00, df_yandex01, df_yandex02, df_yandex03, df_yandex04, df_yandex05):\n",
    "    # TODO\n",
    "    d_examples = {'id': [None, None], 'owners_schema': [0, 0], 'key_point': [0, 0], 'linked_point': [0, 0],\n",
    "                 'key_records_id': [0, 0], 'linked_records_id': [0, 0], 'stats_sheet': [0, 0],\n",
    "                 'demo_time_m': [0.0, 0.0],\n",
    "                 'link_type': [0, 0], 'color': [0, 0]}\n",
    "    return pd.DataFrame(data=d_examples)\n",
    "\n",
    "df_case_graphs = pd.concat([pd.DataFrame(data=d_case_graphs, index={1,2}), step03_make_case_graphs(1, df_case_records,\n",
    "    df_inet_geo2_dicts, df_troyka_lines, df_troyka_stations, df_troyka_entrance_stations,\n",
    "    df_maxima_20170615_dicts, df_yandex_label_codes01, df_yandex_line_codes02, df_yandex_station_codes03,\n",
    "    df_yandex_link_codes04, df_yandex_transfer_codes05)])\n",
    "print (df_case_graphs.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def step04_make_case_stats(schema, df_records, df_inet_geo2, df_troyka_lines, df_troyka_entrances,\n",
    "                           df_maxima00, df_yandex01, df_yandex02, df_yandex03, df_yandex04, df_yandex05):\n",
    "    # TODO\n",
    "    d_examples = {'id': [None, None], 'graphs_id': [0, 0], 'sheet': [0, 0], 'resource_type': [99, 99],\n",
    "                       'resource_code1': [1, 1], 'resource_code2': [2, 2],\n",
    "                       'ts': [0, 0], 'duration': [15*60, 15*60], 'avg_time_m': [90, 100]}\n",
    "    return pd.DataFrame(data=d_examples)\n",
    "\n",
    "#df_case_stats = pd.concat([pd.DataFrame(data=d_case_stats, index={1,2}), step04_make_case_stats(1, df_case_records,\n",
    "#    df_inet_geo2_dicts, df_troyka_line_stations, df_troyka_entrance_stations,\n",
    "#    df_maxima_20170615_dicts, df_yandex_label_codes01, df_yandex_line_codes02, df_yandex_station_codes03,\n",
    "#    df_yandex_link_codes04, df_yandex_transfer_codes05)])\n",
    "#print (df_case_stats.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def step05_make_case_routes(schema, number, df_records, df_graphs, df_stats, from_maxima_code, to_maxima_code):\n",
    "    # TODO: по кратчайшему\n",
    "    d_examples = {'id': [None, None], 'owners_id': [0, 0], 'number': [1, 1], 'profiles_id': [0, 0], 'step': [1, 2],\n",
    "                 'graphs_id': [0, 0],\n",
    "                 'from_key_point': [1, 2], 'to_linked_point': [2, 1],\n",
    "                 'flags': [0, 0], 'probability': [1.0, 1.0], 'time_m': [0.0, 0.0]}\n",
    "    return pd.DataFrame(data=d_examples)\n",
    "\n",
    "#df_case_routes = pd.concat([pd.DataFrame(data=d_case_routes, index={1,2}), step05_make_case_routes(1, 1, df_case_records,\n",
    "#    df_case_graphs, df_case_stats, 'Проспект Мира', 'Калужская')])\n",
    "#print (df_case_routes.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def step06_make_case_profiles(schema, number, df_routes, mobile_tel, fio):\n",
    "    # TODO\n",
    "    d_examples = {'id': [1, 2], 'owners_code': [1, 1], 'mobile_tel': ['1-1', '2-2'],\n",
    "                 'fio': ['A.A.A.', 'B.B.B.']}\n",
    "    return pd.DataFrame(data=d_examples)\n",
    "\n",
    "#df_case_profiles = pd.concat([pd.DataFrame(data=d_case_profiles, index={1,2}), step06_make_case_profiles(1, 1, df_case_routes, '7(999)', 'Иванов')])\n",
    "#print (df_case_profiles.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved case_owners.csv\n",
      "Saved case_graphs.csv\n",
      "Saved case_routes.csv\n",
      "Saved case_profiles.csv\n",
      "Saved case_records.csv\n",
      "Saved case_stats.csv\n",
      "Saved inet_geo2_dicts.csv\n",
      "Saved troyka_line_codes.csv\n",
      "Saved troyka_station_codes.csv\n",
      "Saved troyka_entrance_station_codes.csv\n",
      "Saved maxima_2017-06-15.csv\n",
      "Saved yandex_label_codes01.csv\n",
      "Saved yandex_line_codes02.csv\n",
      "Saved yandex_station_codes03.csv\n",
      "Saved yandex_link_codes04.csv\n",
      "Saved yandex_transfer_codes05.csv\n",
      "Saved check_lines.csv\n",
      "Saved check_lines_r.csv\n",
      "Saved check_stations_r.csv\n",
      "Saved maxima_lines_nsi.csv\n",
      "Saved yandex_lines_nsi.csv\n",
      "Saved maxima_stations_nsi.csv\n",
      "Saved yandex_stations_nsi.csv\n"
     ]
    }
   ],
   "source": [
    "outdir = os.path.join(data_dir, 'temp__result')\n",
    "\n",
    "import os\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)\n",
    "\n",
    "m_case_owners = 'case_owners.csv'\n",
    "df_case_owners.to_csv(os.path.join(outdir, m_case_owners), sep=';', index=False)\n",
    "print (\"Saved \" + m_case_owners)\n",
    "\n",
    "m_case_graphs = 'case_graphs.csv'\n",
    "df_case_graphs.to_csv(os.path.join(outdir, m_case_graphs), sep=';', index=False)\n",
    "print (\"Saved \" + m_case_graphs)\n",
    "\n",
    "m_case_routes = 'case_routes.csv'\n",
    "df_case_routes.to_csv(os.path.join(outdir, m_case_routes), sep=';', index=False)\n",
    "print (\"Saved \" + m_case_routes)\n",
    "\n",
    "m_case_profiles = 'case_profiles.csv'\n",
    "df_case_profiles.to_csv(os.path.join(outdir, m_case_profiles), sep=';', index=False)\n",
    "print (\"Saved \" + m_case_profiles)\n",
    "\n",
    "m_case_records = 'case_records.csv'\n",
    "df_case_records.to_csv(os.path.join(outdir, m_case_records), sep=';', index=False)\n",
    "print (\"Saved \" + m_case_records)\n",
    "\n",
    "m_case_stats = 'case_stats.csv'\n",
    "df_case_stats.to_csv(os.path.join(outdir, m_case_stats), sep=';', index=False)\n",
    "print (\"Saved \" + m_case_stats)\n",
    "\n",
    "m_inet_geo2_dicts = 'inet_geo2_dicts.csv'\n",
    "df_inet_geo2_dicts.to_csv(os.path.join(outdir, m_inet_geo2_dicts), sep=';', index=False)\n",
    "print (\"Saved \" + m_inet_geo2_dicts)\n",
    "\n",
    "m_troyka_lines = 'troyka_line_codes.csv'\n",
    "df_troyka_lines.to_csv(os.path.join(outdir, m_troyka_lines), sep=';', index=False)\n",
    "print (\"Saved \" + m_troyka_lines)\n",
    "\n",
    "m_troyka_stations = 'troyka_station_codes.csv'\n",
    "df_troyka_stations.to_csv(os.path.join(outdir, m_troyka_stations), sep=';', index=False)\n",
    "print (\"Saved \" + m_troyka_stations)\n",
    "\n",
    "m_troyka_entrance_stations = 'troyka_entrance_station_codes.csv'\n",
    "df_troyka_entrance_stations.to_csv(os.path.join(outdir, m_troyka_entrance_stations), sep=';', index=False)\n",
    "print (\"Saved \" + m_troyka_entrance_stations)\n",
    "\n",
    "m_maxima_20170615_dicts = 'maxima_2017-06-15.csv'\n",
    "df_maxima_20170615_dicts.to_csv(os.path.join(outdir, m_maxima_20170615_dicts), sep=';', index=False)\n",
    "print (\"Saved \" + m_maxima_20170615_dicts)\n",
    "\n",
    "m_yandex_label_codes01 = 'yandex_label_codes01.csv'\n",
    "df_yandex_label_codes01.to_csv(os.path.join(outdir, m_yandex_label_codes01), sep=';', index=False)\n",
    "print (\"Saved \" + m_yandex_label_codes01)\n",
    "\n",
    "m_yandex_line_codes02 = 'yandex_line_codes02.csv'\n",
    "df_yandex_line_codes02.to_csv(os.path.join(outdir, m_yandex_line_codes02), sep=';', index=False)\n",
    "print (\"Saved \" + m_yandex_line_codes02)\n",
    "\n",
    "m_yandex_station_codes03 = 'yandex_station_codes03.csv'\n",
    "df_yandex_station_codes03.to_csv(os.path.join(outdir, m_yandex_station_codes03), sep=';', index=False)\n",
    "print (\"Saved \" + m_yandex_station_codes03)\n",
    "\n",
    "m_yandex_link_codes04 = 'yandex_link_codes04.csv'\n",
    "df_yandex_link_codes04.to_csv(os.path.join(outdir, m_yandex_link_codes04), sep=';', index=False)\n",
    "print (\"Saved \" + m_yandex_link_codes04)\n",
    "\n",
    "m_yandex_transfer_codes05 = 'yandex_transfer_codes05.csv'\n",
    "df_yandex_transfer_codes05.to_csv(os.path.join(outdir, m_yandex_transfer_codes05), sep=';', index=False)\n",
    "print (\"Saved \" + m_yandex_transfer_codes05)\n",
    "\n",
    "m_check_lines = 'check_lines.csv'\n",
    "df_check_lines.to_csv(os.path.join(outdir, m_check_lines), sep=';', index=False)\n",
    "print (\"Saved \" + m_check_lines)\n",
    "\n",
    "m_check_lines_r = 'check_lines_r.csv'\n",
    "df_check_lines_r.to_csv(os.path.join(outdir, m_check_lines_r), sep=';', index=False)\n",
    "print (\"Saved \" + m_check_lines_r)\n",
    "\n",
    "m_check_stations_r = 'check_stations_r.csv'\n",
    "df_check_stations_r.to_csv(os.path.join(outdir, m_check_stations_r), sep=';', index=False)\n",
    "print (\"Saved \" + m_check_stations_r)\n",
    "\n",
    "m_maxima_lines_nsi = 'maxima_lines_nsi.csv'\n",
    "df_maxima_lines_nsi.to_csv(os.path.join(outdir, m_maxima_lines_nsi), sep=';', index=False)\n",
    "print (\"Saved \" + m_maxima_lines_nsi)\n",
    "\n",
    "m_yandex_lines_nsi = 'yandex_lines_nsi.csv'\n",
    "df_yandex_lines_nsi.to_csv(os.path.join(outdir, m_yandex_lines_nsi), sep=';', index=False)\n",
    "print (\"Saved \" + m_yandex_lines_nsi)\n",
    "\n",
    "m_maxima_stations_nsi = 'maxima_stations_nsi.csv'\n",
    "df_maxima_stations_nsi.to_csv(os.path.join(outdir, m_maxima_stations_nsi), sep=';', index=False)\n",
    "print (\"Saved \" + m_maxima_stations_nsi)\n",
    "\n",
    "m_yandex_stations_nsi = 'yandex_stations_nsi.csv'\n",
    "df_yandex_stations_nsi.to_csv(os.path.join(outdir, m_yandex_stations_nsi), sep=';', index=False)\n",
    "print (\"Saved \" + m_yandex_stations_nsi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
